{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2: Vector Searching\n",
    "\n",
    "Vector search leverages machine learning to capture the meaning and context of unstructured data, including text and images, transforming it into a numeric representation. Frequently used for semantic search, vector search finds similar data using approximate nearest neighbor algorithms.\n",
    "\n",
    "Vector search engines - known as vector databases, semantic, or cosine search - find the nearest neighbors to a given (vectorized) query. Where traditional search relies on mentions of keywords, lexical similarity, and the frequency of word occurrences, vector search engines use distances in the embedding space to represent similarity. Finding related data becomes searching for nearest neighbors of the query.\n",
    "\n",
    "### Qdrant\n",
    "\n",
    "Qdrant is an open-source vector search engine, a dedicates solution built in Rust for scalable vector search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "import requests\n",
    "from fastembed import TextEmbedding\n",
    "import json\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<qdrant_client.qdrant_client.QdrantClient at 0x11913aea0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant = QdrantClient(\"http://localhost:6333\")\n",
    "\n",
    "qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset\n",
    "\n",
    "The dataset has three course types:\n",
    "- data-engineering-zoomcamp\n",
    "- machine-learning-zoomcamp\n",
    "- mlops-zoomcamp\n",
    "\n",
    "Each course includes a collection of:\n",
    "- *question:* student's question\n",
    "- *text:* anwser to student's question\n",
    "- *section:* course section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "\n",
    "response = requests.get(docs_url)\n",
    "documents_raw = response.json()\n",
    "\n",
    "documents_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform documents into embeddings\n",
    "\n",
    "As we are building a Q&A RAG system, the `question` and `text` fields will be converted to embeddings to find the most relevant answer to a given question.\n",
    "\n",
    "The `course` and `section` fields can be stored as metadata to provide more context when the someone wants to ask question related to a specific course or a specific course's section.\n",
    "\n",
    "#### How to choose the embedding model?\n",
    "\n",
    "It depends on many factors:\n",
    "- the task, data modality and specifications\n",
    "- the trade-off between search precision and resource usage (larger embeddings requeri more storage and memory)\n",
    "- the cost of inference third-party provider\n",
    "\n",
    "FastEmbed is an optimized embedding solition designed for Qdrant. It supports:\n",
    "- dense embeddings for text and images (the most common type in vector search)\n",
    "- sparse embeddings\n",
    "- multivector embeddings\n",
    "- rerankers\n",
    "\n",
    "FastEmbed's integration with Qdrant allows to directly pass text or images to the Qdrant client for embedding.\n",
    "\n",
    "#### Find the most suitable embedding model\n",
    "\n",
    "- Use a small embedding model (e.g. 515 dimensions) and suitable for english text.\n",
    "- Unimodal model once we are not including images in the search, only text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMENSIONALITY = 512\n",
    "\n",
    "for model in TextEmbedding.list_supported_models():\n",
    "    if model[\"dim\"] == EMBEDDING_DIMENSIONALITY:\n",
    "        print(json.dumps(model, indent = 2))\n",
    "\n",
    "embedding_model = \"jinaai/jina-embeddings-v2-small-en\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Qdrant Collection\n",
    "\n",
    "A *Collection* in Qdrant is a container with a set of data points that belongs to a specific domain/entity we want to search for. It has:\n",
    "- **Name**: A unique identifier for the collection.\n",
    "- **Vector size:** The dimensionality of the vector.\n",
    "- **Distance metric:** The method used to measure similiarity between vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"zoomcamp-rag\"\n",
    "\n",
    "qdrant.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create, Embed and Insert a Point into the Collection\n",
    "\n",
    "A *Point* is the main entity of Qdrant platform. It represents the data point in a high-dimensional space enriched with:\n",
    "- **Identifier:** A unique identifier for the data point.\n",
    "- **Vector** (embeddings): It captures the semantic essence of the data.\n",
    "- **Payload**: It is a JSON object with additioanl metadata. This metadata becomes especially useful when applying filters or sorting during searching.\n",
    "\n",
    "Before uploading the Points in the Collection, each document is embedded according the selected model (`jinaai/jina-embeddings-v2-small-en`), using the FastEmbed library. The, the generated points will be inserted into the Collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774fd8a5d63744b4a878c2c758d3fd72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd42407b41e4f5aa5eabbdded60badd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1069be473d4b4ab3ac168cf0a79e845a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/367 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e0eb75a12948c7beea23f1b8fd3aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f8cc87bcce45c2acbc0f9fa3387745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/model.onnx:   0%|          | 0.00/130M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b1a5fd09bb4cb988c0cb285fb26c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = []\n",
    "index = 0\n",
    "\n",
    "\n",
    "for course in documents_raw:\n",
    "    for doc in course[\"documents\"]:\n",
    "        point = models.PointStruct(\n",
    "            id=index,\n",
    "            vector=models.Document(text=doc[\"text\"], model=embedding_model),\n",
    "            payload={\n",
    "                \"text\": doc[\"text\"],\n",
    "                \"section\": doc[\"section\"],\n",
    "                \"course\": course[\"course\"]\n",
    "            }\n",
    "        )\n",
    "        points.append(point)\n",
    "        index += 1\n",
    "\n",
    "qdrant.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Semantic Search - Similarity Search\n",
    "\n",
    "1. Qdrant compares the query's vector to stored vectors, using the distance metric defined previously. \n",
    "2. The closest matches are returned, ranked by similarity. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, limit=1):\n",
    "    return qdrant.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document(\n",
    "            text=query,\n",
    "            model=embedding_model\n",
    "        ),\n",
    "        limit=limit,\n",
    "        with_payload=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course = random.choice(documents_raw)\n",
    "course_doc = random.choice(course[\"documents\"])\n",
    "random_question = course_doc[\"question\"]\n",
    "\n",
    "random_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "\n",
      "Top Retrieved Answer:\n",
      "You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "Original Answer:\n",
      "You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n"
     ]
    }
   ],
   "source": [
    "search_result = search(query=random_question)\n",
    "search_result\n",
    "\n",
    "print(f\"Question:\\n{course_doc['question']}\\n\")\n",
    "print(\"Top Retrieved Answer:\\n{}\\n\".format(search_result.points[0].payload['text']))\n",
    "print(\"Original Answer:\\n{}\".format(course_doc['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No, late submissions are not allowed. But if the form is still not closed and it’s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\\nOlder news:[source1] [source2]'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results = search(query=\"What if I submit homeworks late?\")\n",
    "answer = search_results.points[0].payload[\"text\"]\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Semantic Search - Similarity Search with Filters\n",
    "\n",
    "Qdrant's custom vector index implementation allows for precise and scalable vector search with filtering conditions.\n",
    "\n",
    "For example, we can search for an answer related to a specific course. Using the `must` filter ensures that all specified conditions are met for a data point. \n",
    "\n",
    "Qdrant also supports other filter types such as `should`, `must_not`, `range`, and more.\n",
    "\n",
    "To enable efficient filtering, we need to activate the indexing of payload fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=2, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"course\",\n",
    "    field_schema=\"keyword\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_by_filter(query, filter_key, filter_value, limit = 1):\n",
    "    return qdrant.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document(\n",
    "            text=query,\n",
    "            model=embedding_model\n",
    "        ),\n",
    "        query_filter=models.Filter(\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=filter_key,\n",
    "                    match=models.MatchValue(value=filter_value)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=limit,\n",
    "        with_payload=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please choose the closest one to your answer. Also do not post your answer in the course slack channel.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_filter_results = search_by_filter(query=\"What if I submit homeworks late?\", filter_key=\"course\", filter_value=\"mlops-zoomcamp\")\n",
    "\n",
    "answer_filtered = search_filter_results.points[0].payload[\"text\"]\n",
    "\n",
    "answer_filtered\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
