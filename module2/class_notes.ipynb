{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2: Vector Searching\n",
    "\n",
    "Vector search leverages machine learning to capture the meaning and context of unstructured data, including text and images, transforming it into a numeric representation. Frequently used for semantic search, vector search finds similar data using approximate nearest neighbor algorithms.\n",
    "\n",
    "Vector search engines - known as vector databases, semantic, or cosine search - find the nearest neighbors to a given (vectorized) query. Where traditional search relies on mentions of keywords, lexical similarity, and the frequency of word occurrences, vector search engines use distances in the embedding space to represent similarity. Finding related data becomes searching for nearest neighbors of the query.\n",
    "\n",
    "### Qdrant\n",
    "\n",
    "Qdrant is an open-source vector search engine, a dedicates solution built in Rust for scalable vector search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "import requests\n",
    "from fastembed import TextEmbedding\n",
    "import json\n",
    "import random\n",
    "import uuid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<qdrant_client.qdrant_client.QdrantClient at 0x11f7c2c30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant = QdrantClient(\"http://localhost:6333\")\n",
    "\n",
    "qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset\n",
    "\n",
    "The dataset has three course types:\n",
    "- data-engineering-zoomcamp\n",
    "- machine-learning-zoomcamp\n",
    "- mlops-zoomcamp\n",
    "\n",
    "Each course includes a collection of:\n",
    "- *question:* student's question\n",
    "- *text:* anwser to student's question\n",
    "- *section:* course section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "\n",
    "response = requests.get(docs_url)\n",
    "documents_raw = response.json()\n",
    "\n",
    "documents_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform documents into embeddings\n",
    "\n",
    "As we are building a Q&A RAG system, the `question` and `text` fields will be converted to embeddings to find the most relevant answer to a given question.\n",
    "\n",
    "The `course` and `section` fields can be stored as metadata to provide more context when the someone wants to ask question related to a specific course or a specific course's section.\n",
    "\n",
    "#### How to choose the embedding model?\n",
    "\n",
    "It depends on many factors:\n",
    "- the task, data modality and specifications\n",
    "- the trade-off between search precision and resource usage (larger embeddings requeri more storage and memory)\n",
    "- the cost of inference third-party provider\n",
    "\n",
    "FastEmbed is an optimized embedding solition designed for Qdrant. It supports:\n",
    "- dense embeddings for text and images (the most common type in vector search)\n",
    "- sparse embeddings\n",
    "- multivector embeddings\n",
    "- rerankers\n",
    "\n",
    "FastEmbed's integration with Qdrant allows to directly pass text or images to the Qdrant client for embedding.\n",
    "\n",
    "#### Find the most suitable embedding model\n",
    "\n",
    "- Use a small embedding model (e.g. 515 dimensions) and suitable for english text.\n",
    "- Unimodal model once we are not including images in the search, only text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMENSIONALITY = 512\n",
    "\n",
    "for model in TextEmbedding.list_supported_models():\n",
    "    if model[\"dim\"] == EMBEDDING_DIMENSIONALITY:\n",
    "        print(json.dumps(model, indent = 2))\n",
    "\n",
    "embedding_model = \"jinaai/jina-embeddings-v2-small-en\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Qdrant Collection\n",
    "\n",
    "A *Collection* in Qdrant is a container with a set of data points that belongs to a specific domain/entity we want to search for. It has:\n",
    "- **Name**: A unique identifier for the collection.\n",
    "- **Vector size:** The dimensionality of the vector.\n",
    "- **Distance metric:** The method used to measure similiarity between vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"zoomcamp-rag\"\n",
    "\n",
    "qdrant.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create, Embed and Insert a Point into the Collection\n",
    "\n",
    "A *Point* is the main entity of Qdrant platform. It represents the data point in a high-dimensional space enriched with:\n",
    "- **Identifier:** A unique identifier for the data point.\n",
    "- **Vector** (embeddings): It captures the semantic essence of the data.\n",
    "- **Payload**: It is a JSON object with additioanl metadata. This metadata becomes especially useful when applying filters or sorting during searching.\n",
    "\n",
    "Before uploading the Points in the Collection, each document is embedded according the selected model (`jinaai/jina-embeddings-v2-small-en`), using the FastEmbed library. The, the generated points will be inserted into the Collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "index = 0\n",
    "\n",
    "\n",
    "for course in documents_raw:\n",
    "    for doc in course[\"documents\"]:\n",
    "        point = models.PointStruct(\n",
    "            id=index,\n",
    "            vector=models.Document(text=doc[\"text\"], model=embedding_model),\n",
    "            payload={\n",
    "                \"text\": doc[\"text\"],\n",
    "                \"section\": doc[\"section\"],\n",
    "                \"course\": course[\"course\"]\n",
    "            }\n",
    "        )\n",
    "        points.append(point)\n",
    "        index += 1\n",
    "\n",
    "qdrant.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Semantic Search - Similarity Search\n",
    "\n",
    "1. Qdrant compares the query's vector to stored vectors, using the distance metric defined previously. \n",
    "2. The closest matches are returned, ranked by similarity. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, limit=1):\n",
    "    return qdrant.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document(\n",
    "            text=query,\n",
    "            model=embedding_model\n",
    "        ),\n",
    "        limit=limit,\n",
    "        with_payload=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Git - How do I include the files in the Mage repo (including exercise files and homework) in a personal copy of the Data Engineering Zoomcamp repo?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course = random.choice(documents_raw)\n",
    "course_doc = random.choice(course[\"documents\"])\n",
    "random_question = course_doc[\"question\"]\n",
    "\n",
    "random_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Git - How do I include the files in the Mage repo (including exercise files and homework) in a personal copy of the Data Engineering Zoomcamp repo?\n",
      "\n",
      "Top Retrieved Answer:\n",
      "Assuming you downloaded the Mage repo in the week 2 folder of the Data Engineering Zoomcamp, you might want to include your mage copy, demo pipelines and homework within your personal copy of the Data Engineering Zoomcamp repo. This will not work by default, because GitHub sees them as two separate repositories, and one does not track the other. To add the Mage files to your main DE Zoomcamp repo, you will need to:\n",
      "Move the contents of the .gitignore file in your main .gitignore.\n",
      "Use the terminal to cd into the Mage folder and:\n",
      "run “git remote remove origin” to de-couple the Mage repo,\n",
      "run “rm -rf .git” to delete local git files,\n",
      "run “git add .” to add the current folder as changes to stage, commit and push.\n",
      "\n",
      "Original Answer:\n",
      "Assuming you downloaded the Mage repo in the week 2 folder of the Data Engineering Zoomcamp, you might want to include your mage copy, demo pipelines and homework within your personal copy of the Data Engineering Zoomcamp repo. This will not work by default, because GitHub sees them as two separate repositories, and one does not track the other. To add the Mage files to your main DE Zoomcamp repo, you will need to:\n",
      "Move the contents of the .gitignore file in your main .gitignore.\n",
      "Use the terminal to cd into the Mage folder and:\n",
      "run “git remote remove origin” to de-couple the Mage repo,\n",
      "run “rm -rf .git” to delete local git files,\n",
      "run “git add .” to add the current folder as changes to stage, commit and push.\n"
     ]
    }
   ],
   "source": [
    "search_result = search(query=random_question)\n",
    "search_result\n",
    "\n",
    "print(f\"Question:\\n{course_doc['question']}\\n\")\n",
    "print(\"Top Retrieved Answer:\\n{}\\n\".format(search_result.points[0].payload['text']))\n",
    "print(\"Original Answer:\\n{}\".format(course_doc['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No, late submissions are not allowed. But if the form is still not closed and it’s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\\nOlder news:[source1] [source2]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results = search(query=\"What if I submit homeworks late?\")\n",
    "answer = search_results.points[0].payload[\"text\"]\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Semantic Search - Similarity Search with Filters\n",
    "\n",
    "Qdrant's custom vector index implementation allows for precise and scalable vector search with filtering conditions.\n",
    "\n",
    "For example, we can search for an answer related to a specific course. Using the `must` filter ensures that all specified conditions are met for a data point. \n",
    "\n",
    "Qdrant also supports other filter types such as `should`, `must_not`, `range`, and more.\n",
    "\n",
    "To enable efficient filtering, we need to activate the indexing of payload fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=4, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"course\",\n",
    "    field_schema=\"keyword\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_by_filter(query, filter_key, filter_value, limit = 1):\n",
    "    return qdrant.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document(\n",
    "            text=query,\n",
    "            model=embedding_model\n",
    "        ),\n",
    "        query_filter=models.Filter(\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=filter_key,\n",
    "                    match=models.MatchValue(value=filter_value)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=limit,\n",
    "        with_payload=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please choose the closest one to your answer. Also do not post your answer in the course slack channel.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_filter_results = search_by_filter(query=\"What if I submit homeworks late?\", filter_key=\"course\", filter_value=\"mlops-zoomcamp\")\n",
    "\n",
    "answer_filtered = search_filter_results.points[0].payload[\"text\"]\n",
    "\n",
    "answer_filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing RAG with Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_collection_name = \"zoomcamp-faq\"\n",
    "\n",
    "qdrant.create_collection(\n",
    "    collection_name=faq_collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course[\"course\"]\n",
    "\n",
    "    for doc in course[\"documents\"]:\n",
    "        doc[\"course\"] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "points = []\n",
    "for index, doc in enumerate(documents):\n",
    "    text = doc['question'] + \" \" + doc['text']\n",
    "    vector = models.Document(text=text, model=embedding_model)\n",
    "    point = models.PointStruct(\n",
    "        id=index,\n",
    "        vector=vector,\n",
    "        payload=doc\n",
    "    )\n",
    "\n",
    "    points.append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=1, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant.create_payload_index(\n",
    "    collection_name=faq_collection_name,\n",
    "    field_name=\"course\",\n",
    "    field_schema=\"keyword\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=2, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant.upsert(\n",
    "    collection_name=faq_collection_name,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_question = \"I just discovered the course. Can I still join it?\"\n",
    "faq_course = \"data-engineering-zoomcamp\"\n",
    "\n",
    "result_points = qdrant.query_points(\n",
    "    collection_name=faq_collection_name,\n",
    "    query=models.Document(\n",
    "        text=faq_question,\n",
    "        model=embedding_model\n",
    "    ),\n",
    "    query_filter=models.Filter(\n",
    "        must=[\n",
    "            models.FieldCondition(\n",
    "                key=\"course\",\n",
    "                match=models.MatchValue(value=faq_course)\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "search_results = []\n",
    "\n",
    "for point in result_points.points:\n",
    "    answer = point.payload\n",
    "    search_results.append(answer)\n",
    "\n",
    "search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Search\n",
    "\n",
    "Combination of **Semantic search** and **Keyword-based search**.\n",
    "\n",
    "\n",
    "FastEmbed comes with a BM25 implemetation that we can use to embedding our data points. The data upload is much more fast when compared to dense embedding models, because BM25 algorithm does not require any neural network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Data Points using BM25 as embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_collection_name = \"zoomcamp-sparse\"\n",
    "\n",
    "qdrant.create_collection(\n",
    "    collection_name=sparse_collection_name,\n",
    "    sparse_vectors_config={\n",
    "        \"bm25\": models.SparseVectorParams(\n",
    "            modifier=models.Modifier.IDF\n",
    "        )\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for course in documents_raw:\n",
    "    for doc in course[\"documents\"]:\n",
    "        qdrant.upsert(\n",
    "            collection_name=sparse_collection_name,\n",
    "            points=[\n",
    "                models.PointStruct(\n",
    "                    id=uuid.uuid4().hex,\n",
    "                    vector={\n",
    "                        \"bm25\": models.Document(\n",
    "                            text=doc[\"text\"],\n",
    "                            model=\"Qdrant/bm25\"\n",
    "                        )},\n",
    "                    payload={\n",
    "                        \"text\": doc[\"text\"],\n",
    "                        \"section\": doc[\"section\"],\n",
    "                        \"course\": course[\"course\"]\n",
    "                    }\n",
    "                )\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search with BM25\n",
    "\n",
    "Sparse vectors can return no results if none of the keywrods from the query were used in the documents. No matter if they are similar. Semantic does not matter, only terminology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, limit=1):\n",
    "    results = qdrant.query_points(\n",
    "        collection_name=sparse_collection_name,\n",
    "        query=models.Document(\n",
    "            text=query,\n",
    "            model=\"Qdrant/bm25\"\n",
    "        ),\n",
    "        using=\"bm25\",\n",
    "        limit=limit,\n",
    "        with_payload=True\n",
    "    )\n",
    "\n",
    "    return results.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"Qdrant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You can use round() function or f-strings\\nround(number, 4)  - this will round number up to 4 decimal places\\nprint(f'Average mark for the Homework is {avg:.3f}') - using F string\\nAlso there is pandas.Series. round idf you need to round values in the whole Series\\nPlease check the documentation\\nhttps://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.round.html#pandas.Series.round\\nAdded by Olga Rudakova\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = search(\"pandas\")\n",
    "\n",
    "results[0].payload[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Stage Queries\n",
    "\n",
    "There are use-cases when the best search is obtained by combining multiple queries, or by performning in more than one stage.\n",
    "\n",
    "The main component for making the combinations of queries possible is the **prefetch** parameter, which enables making sub-requests.\n",
    "\n",
    "Whenever a query has at least one prefetch, Qdrant will:\n",
    "\n",
    "1. Perform the prefetch query \n",
    "2. Apply the main query over the results of its prefetch(es)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_dense_collection_name = \"zoomcamp-sparse-and-dense\"\n",
    "\n",
    "qdrant.create_collection(\n",
    "    collection_name=sparse_dense_collection_name,\n",
    "    vectors_config={\n",
    "        \"jina-small\": models.VectorParams(\n",
    "            size=512,\n",
    "            distance=models.Distance.COSINE,\n",
    "        ),\n",
    "    },\n",
    "    sparse_vectors_config={\n",
    "        \"bm25\": models.SparseVectorParams(\n",
    "            modifier=models.Modifier.IDF\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for course in documents_raw:\n",
    "    for doc in course[\"documents\"]:\n",
    "        qdrant.upsert(\n",
    "            collection_name=sparse_dense_collection_name,\n",
    "            points=[\n",
    "                models.PointStruct(\n",
    "                    id=uuid.uuid4().hex,\n",
    "                    vector={\n",
    "                        \"jina-small\": models.Document(\n",
    "                            text=doc[\"text\"],\n",
    "                            model=\"jinaai/jina-embeddings-v2-small-en\"\n",
    "                        ),\n",
    "                        \"bm25\": models.Document(\n",
    "                            text=doc[\"text\"],\n",
    "                            model=\"Qdrant/bm25\"\n",
    "                        )\n",
    "                    },\n",
    "                    payload={\n",
    "                        \"text\": doc[\"text\"],\n",
    "                        \"section\": doc[\"section\"],\n",
    "                        \"course\": course[\"course\"]\n",
    "                    }\n",
    "                )\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_stage_search(query, limit=1):\n",
    "    results = qdrant.query_points(\n",
    "        collection_name=sparse_dense_collection_name,\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model=\"jinaai/jina-embeddings-v2-small-en\",\n",
    "                ),\n",
    "                using=\"jina-small\",\n",
    "                # Prefetch ten times more results, then\n",
    "                # expected to return, so we can really rerank\n",
    "                limit=(10 * limit)\n",
    "            )\n",
    "        ],\n",
    "        query=models.Document(\n",
    "            text=query,\n",
    "            model=\"Qdrant/bm25\"\n",
    "        ),\n",
    "        using=\"bm25\",\n",
    "        limit=limit,\n",
    "        with_payload=True\n",
    "    )\n",
    "\n",
    "    return results.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"Even though the upload works using aws cli and boto3 in Jupyter notebook.\\nSolution set the AWS_PROFILE environment variable (the default profile is called default)\",\n",
      "  \"section\": \"Module 4: Deployment\",\n",
      "  \"question\": \"Uploading to s3 fails with An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The AWS Access Key Id you provided does not exist in our records.\\\"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "random.seed(202506)\n",
    "\n",
    "course = random.choice(documents_raw)\n",
    "course_piece = random.choice(course[\"documents\"])\n",
    "print(json.dumps(course_piece, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Problem description. How can we connect s3 bucket to MLFLOW?\\nSolution: Use boto3 and AWS CLI to store access keys. The access keys are what will be used by boto3 (AWS' Python API tool) to connect with the AWS servers. If there are no Access Keys how can they make sure that they have the right to access this Bucket? Maybe you're a malicious actor (Hacker for ex). The keys must be present for boto3 to talk to the AWS servers and they will provide access to the Bucket if you possess the right permissions. You can always set the Bucket as public so anyone can access it, now you don't need access keys because AWS won't care.\\nRead more here: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html\\nAdded by Akshit Miglani\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = multi_stage_search(course_piece[\"question\"])\n",
    "\n",
    "results[0].payload[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Search and Fusion\n",
    "\n",
    "Hybrid Search is a technique for combining results coming from different search methods - dense and sparse. Dense and sparse search scores cannot be compared directly, so we need another method that will order the final results somehow.\n",
    "\n",
    "There are two important terms for it:\n",
    "- **Fusion**\n",
    "- **Reranking**\n",
    "\n",
    "#### Fusion \n",
    "Fusion is a set of methods which work on the scores/ranking as returned by the individual methods. There are many ways of how to achieve that, but **Reciprocal Rank Fusion** is the most popular one. It is based on the rankings of the documents in each methods (dense and sparse ranking), and these rankings are used to calculate the final scores. The final ranking is calculated based on the RRF score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reciprocal Rank Fusion search\n",
    "\n",
    "def rrf_search(query, limit=1):\n",
    "    results = qdrant.query_points(\n",
    "        collection_name=sparse_dense_collection_name,\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model= \"jinaai/jina-embeddings-v2-small-en\"\n",
    "                ),\n",
    "                using=\"jina-small\",\n",
    "                limit=(5 * limit)\n",
    "            ),\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model=\"Qdrant/bm25\"\n",
    "                    ),\n",
    "                using=\"bm25\",\n",
    "                limit=(5 * limit)\n",
    "                )\n",
    "        ],\n",
    "        query=models.FusionQuery(fusion=models.Fusion.RRF),\n",
    "        with_payload=True\n",
    "    )\n",
    "\n",
    "    return results.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"Even though the upload works using aws cli and boto3 in Jupyter notebook.\\nSolution set the AWS_PROFILE environment variable (the default profile is called default)\",\n",
      "  \"section\": \"Module 4: Deployment\",\n",
      "  \"question\": \"Uploading to s3 fails with An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The AWS Access Key Id you provided does not exist in our records.\\\"\"\n",
      "}\n",
      "Problem description. How can we connect s3 bucket to MLFLOW?\n",
      "Solution: Use boto3 and AWS CLI to store access keys. The access keys are what will be used by boto3 (AWS' Python API tool) to connect with the AWS servers. If there are no Access Keys how can they make sure that they have the right to access this Bucket? Maybe you're a malicious actor (Hacker for ex). The keys must be present for boto3 to talk to the AWS servers and they will provide access to the Bucket if you possess the right permissions. You can always set the Bucket as public so anyone can access it, now you don't need access keys because AWS won't care.\n",
      "Read more here: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html\n",
      "Added by Akshit Miglani\n"
     ]
    }
   ],
   "source": [
    "results = rrf_search(course_piece[\"question\"])\n",
    "print(json.dumps(course_piece, indent=2))\n",
    "print(results[0].payload[\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
