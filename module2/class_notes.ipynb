{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2: Vector Searching\n",
    "\n",
    "Vector search leverages machine learning to capture the meaning and context of unstructured data, including text and images, transforming it into a numeric representation. Frequently used for semantic search, vector search finds similar data using approximate nearest neighbor algorithms.\n",
    "\n",
    "Vector search engines - known as vector databases, semantic, or cosine search - find the nearest neighbors to a given (vectorized) query. Where traditional search relies on mentions of keywords, lexical similarity, and the frequency of word occurrences, vector search engines use distances in the embedding space to represent similarity. Finding related data becomes searching for nearest neighbors of the query.\n",
    "\n",
    "### Qdrant\n",
    "\n",
    "Qdrant is an open-source vector search engine, a dedicates solution built in Rust for scalable vector search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "import requests\n",
    "from fastembed import TextEmbedding\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<qdrant_client.qdrant_client.QdrantClient at 0x128700110>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant = QdrantClient(\"http://localhost:6333\")\n",
    "\n",
    "qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset\n",
    "\n",
    "The dataset has three course types:\n",
    "- data-engineering-zoomcamp\n",
    "- machine-learning-zoomcamp\n",
    "- mlops-zoomcamp\n",
    "\n",
    "Each course includes a collection of:\n",
    "- *question:* student's question\n",
    "- *text:* anwser to student's question\n",
    "- *section:* course section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "\n",
    "response = requests.get(docs_url)\n",
    "documents_raw = response.json()\n",
    "\n",
    "documents_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform documents into embeddings\n",
    "\n",
    "As we are building a Q&A RAG system, the `question` and `text` fields will be converted to embeddings to find the most relevant answer to a given question.\n",
    "\n",
    "The `course` and `section` fields can be stored as metadata to provide more context when the someone wants to ask question related to a specific course or a specific course's section.\n",
    "\n",
    "#### How to choose the embedding model?\n",
    "\n",
    "It depends on many factors:\n",
    "- the task, data modality and specifications\n",
    "- the trade-off between search precision and resource usage (larger embeddings requeri more storage and memory)\n",
    "- the cost of inference third-party provider\n",
    "\n",
    "FastEmbed is an optimized embedding solition designed for Qdrant. It supports:\n",
    "- dense embeddings for text and images (the most common type in vector search)\n",
    "- sparse embeddings\n",
    "- multivector embeddings\n",
    "- rerankers\n",
    "\n",
    "FastEmbed's integration with Qdrant allows to directly pass text or images to the Qdrant client for embedding.\n",
    "\n",
    "#### Find the most suitable embedding model\n",
    "\n",
    "- Use a small embedding model (e.g. 515 dimensions) and suitable for english text.\n",
    "- Unimodal model once we are not including images in the search, only text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMENSIONALITY = 512\n",
    "\n",
    "for model in TextEmbedding.list_supported_models():\n",
    "    if model[\"dim\"] == EMBEDDING_DIMENSIONALITY:\n",
    "        print(json.dumps(model, indent = 2))\n",
    "\n",
    "embedding_model = \"jinaai/jina-embeddings-v2-small-en\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
